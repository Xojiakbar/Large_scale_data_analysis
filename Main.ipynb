{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Question 1a: Get to know the Data: WordCloud"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\bxoji\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\deprecation.py:143: FutureWarning: The sklearn.feature_extraction.stop_words module is  deprecated in version 0.22 and will be removed in version 0.24. The corresponding classes / functions should instead be imported from sklearn.feature_extraction.text. Anything that cannot be imported from sklearn.feature_extraction.text is now part of the private API.\n",
      "  warnings.warn(message, FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "# Start with loading all necessary libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from os import path\n",
    "import re\n",
    "from PIL import Image\n",
    "from wordcloud import WordCloud, STOPWORDS, ImageColorGenerator\n",
    "import matplotlib.pyplot as plt\n",
    "import string\n",
    "from collections import defaultdict\n",
    "\n",
    "#sklearn libraries\n",
    "import sklearn\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction import stop_words as sk_sw\n",
    "from sklearn.model_selection import RepeatedKFold, cross_val_score\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn import model_selection, svm\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.decomposition import TruncatedSVD\n",
    "from scipy.sparse import random as sparse_random\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "#keras libraries for CNN\n",
    "#import tensorflow\n",
    "#import keras\n",
    "#from keras.models import Sequential\n",
    "#from keras import layers\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "showing info https://raw.githubusercontent.com/nltk/nltk_data/gh-pages/index.xml\n"
     ]
    }
   ],
   "source": [
    "#library for stop words\n",
    "import nltk\n",
    "nltk.download()\n",
    "from nltk.corpus import stopwords  \n",
    "from nltk.corpus import wordnet as wn\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk import pos_tag"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Title</th>\n",
       "      <th>Content</th>\n",
       "      <th>Label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Netflix is coming to cable boxes, and Amazon i...</td>\n",
       "      <td>if you subscribe to one of three rinky-dink (...</td>\n",
       "      <td>Entertainment</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Pharrell, Iranian President React to Tehran 'H...</td>\n",
       "      <td>pharrell, iranian president react to tehran '...</td>\n",
       "      <td>Entertainment</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Wildlife service seeks comments</td>\n",
       "      <td>the u.s. fish and wildlife service has reopen...</td>\n",
       "      <td>Technology</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Facebook teams up with Storyful to launch 'FB ...</td>\n",
       "      <td>the very nature of social media means it is o...</td>\n",
       "      <td>Technology</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Caesars plans US$880 mln New York casino</td>\n",
       "      <td>caesars plans us$880 mln new york casino jul ...</td>\n",
       "      <td>Business</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>111790</th>\n",
       "      <td>Microsoft requires Office 2013 licensing for s...</td>\n",
       "      <td>in contrast to the muckle of special licenses...</td>\n",
       "      <td>Technology</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>111791</th>\n",
       "      <td>Smallpox vials missing since 1950s found in la...</td>\n",
       "      <td>government workers at a research center near ...</td>\n",
       "      <td>Health</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>111792</th>\n",
       "      <td>Scientists May Have Just Discovered the Key to...</td>\n",
       "      <td>harvard scientists may have just unlocked the...</td>\n",
       "      <td>Health</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>111793</th>\n",
       "      <td>Justin Bieber to plead guilty to DUI</td>\n",
       "      <td>justin bieber to plead guilty to duifri, 13 ju...</td>\n",
       "      <td>Entertainment</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>111794</th>\n",
       "      <td>Tracy Morgan upgraded to fair condition after ...</td>\n",
       "      <td>actor and comedian tracy morgan has been upgr...</td>\n",
       "      <td>Entertainment</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>111795 rows Ã— 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                    Title  \\\n",
       "0       Netflix is coming to cable boxes, and Amazon i...   \n",
       "1       Pharrell, Iranian President React to Tehran 'H...   \n",
       "2                         Wildlife service seeks comments   \n",
       "3       Facebook teams up with Storyful to launch 'FB ...   \n",
       "4                Caesars plans US$880 mln New York casino   \n",
       "...                                                   ...   \n",
       "111790  Microsoft requires Office 2013 licensing for s...   \n",
       "111791  Smallpox vials missing since 1950s found in la...   \n",
       "111792  Scientists May Have Just Discovered the Key to...   \n",
       "111793               Justin Bieber to plead guilty to DUI   \n",
       "111794  Tracy Morgan upgraded to fair condition after ...   \n",
       "\n",
       "                                                  Content          Label  \n",
       "0        if you subscribe to one of three rinky-dink (...  Entertainment  \n",
       "1        pharrell, iranian president react to tehran '...  Entertainment  \n",
       "2        the u.s. fish and wildlife service has reopen...     Technology  \n",
       "3        the very nature of social media means it is o...     Technology  \n",
       "4        caesars plans us$880 mln new york casino jul ...       Business  \n",
       "...                                                   ...            ...  \n",
       "111790   in contrast to the muckle of special licenses...     Technology  \n",
       "111791   government workers at a research center near ...         Health  \n",
       "111792   harvard scientists may have just unlocked the...         Health  \n",
       "111793  justin bieber to plead guilty to duifri, 13 ju...  Entertainment  \n",
       "111794   actor and comedian tracy morgan has been upgr...  Entertainment  \n",
       "\n",
       "[111795 rows x 3 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset = pd.read_csv('train.csv')\n",
    "\n",
    "df = pd.concat([dataset['Title'], dataset['Content'], dataset['Label']], axis=1)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Title</th>\n",
       "      <th>Content</th>\n",
       "      <th>Label</th>\n",
       "      <th>United</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Netflix is coming to cable boxes, and Amazon i...</td>\n",
       "      <td>if you subscribe to one of three rinky-dink (...</td>\n",
       "      <td>Entertainment</td>\n",
       "      <td>Netflix is coming to cable boxes, and Amazon i...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Pharrell, Iranian President React to Tehran 'H...</td>\n",
       "      <td>pharrell, iranian president react to tehran '...</td>\n",
       "      <td>Entertainment</td>\n",
       "      <td>Pharrell, Iranian President React to Tehran 'H...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Wildlife service seeks comments</td>\n",
       "      <td>the u.s. fish and wildlife service has reopen...</td>\n",
       "      <td>Technology</td>\n",
       "      <td>Wildlife service seeks comments  the u.s. fish...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Facebook teams up with Storyful to launch 'FB ...</td>\n",
       "      <td>the very nature of social media means it is o...</td>\n",
       "      <td>Technology</td>\n",
       "      <td>Facebook teams up with Storyful to launch 'FB ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Caesars plans US$880 mln New York casino</td>\n",
       "      <td>caesars plans us$880 mln new york casino jul ...</td>\n",
       "      <td>Business</td>\n",
       "      <td>Caesars plans US$880 mln New York casino  caes...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>111790</th>\n",
       "      <td>Microsoft requires Office 2013 licensing for s...</td>\n",
       "      <td>in contrast to the muckle of special licenses...</td>\n",
       "      <td>Technology</td>\n",
       "      <td>Microsoft requires Office 2013 licensing for s...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>111791</th>\n",
       "      <td>Smallpox vials missing since 1950s found in la...</td>\n",
       "      <td>government workers at a research center near ...</td>\n",
       "      <td>Health</td>\n",
       "      <td>Smallpox vials missing since 1950s found in la...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>111792</th>\n",
       "      <td>Scientists May Have Just Discovered the Key to...</td>\n",
       "      <td>harvard scientists may have just unlocked the...</td>\n",
       "      <td>Health</td>\n",
       "      <td>Scientists May Have Just Discovered the Key to...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>111793</th>\n",
       "      <td>Justin Bieber to plead guilty to DUI</td>\n",
       "      <td>justin bieber to plead guilty to duifri, 13 ju...</td>\n",
       "      <td>Entertainment</td>\n",
       "      <td>Justin Bieber to plead guilty to DUI justin bi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>111794</th>\n",
       "      <td>Tracy Morgan upgraded to fair condition after ...</td>\n",
       "      <td>actor and comedian tracy morgan has been upgr...</td>\n",
       "      <td>Entertainment</td>\n",
       "      <td>Tracy Morgan upgraded to fair condition after ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>111795 rows Ã— 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                    Title  \\\n",
       "0       Netflix is coming to cable boxes, and Amazon i...   \n",
       "1       Pharrell, Iranian President React to Tehran 'H...   \n",
       "2                         Wildlife service seeks comments   \n",
       "3       Facebook teams up with Storyful to launch 'FB ...   \n",
       "4                Caesars plans US$880 mln New York casino   \n",
       "...                                                   ...   \n",
       "111790  Microsoft requires Office 2013 licensing for s...   \n",
       "111791  Smallpox vials missing since 1950s found in la...   \n",
       "111792  Scientists May Have Just Discovered the Key to...   \n",
       "111793               Justin Bieber to plead guilty to DUI   \n",
       "111794  Tracy Morgan upgraded to fair condition after ...   \n",
       "\n",
       "                                                  Content          Label  \\\n",
       "0        if you subscribe to one of three rinky-dink (...  Entertainment   \n",
       "1        pharrell, iranian president react to tehran '...  Entertainment   \n",
       "2        the u.s. fish and wildlife service has reopen...     Technology   \n",
       "3        the very nature of social media means it is o...     Technology   \n",
       "4        caesars plans us$880 mln new york casino jul ...       Business   \n",
       "...                                                   ...            ...   \n",
       "111790   in contrast to the muckle of special licenses...     Technology   \n",
       "111791   government workers at a research center near ...         Health   \n",
       "111792   harvard scientists may have just unlocked the...         Health   \n",
       "111793  justin bieber to plead guilty to duifri, 13 ju...  Entertainment   \n",
       "111794   actor and comedian tracy morgan has been upgr...  Entertainment   \n",
       "\n",
       "                                                   United  \n",
       "0       Netflix is coming to cable boxes, and Amazon i...  \n",
       "1       Pharrell, Iranian President React to Tehran 'H...  \n",
       "2       Wildlife service seeks comments  the u.s. fish...  \n",
       "3       Facebook teams up with Storyful to launch 'FB ...  \n",
       "4       Caesars plans US$880 mln New York casino  caes...  \n",
       "...                                                   ...  \n",
       "111790  Microsoft requires Office 2013 licensing for s...  \n",
       "111791  Smallpox vials missing since 1950s found in la...  \n",
       "111792  Scientists May Have Just Discovered the Key to...  \n",
       "111793  Justin Bieber to plead guilty to DUI justin bi...  \n",
       "111794  Tracy Morgan upgraded to fair condition after ...  \n",
       "\n",
       "[111795 rows x 4 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Joining Title and Content column and separating them with '---' symbol \n",
    "df['United'] = df['Title'] + ' ' + df['Content']\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Stop Wrods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create stopword list:\n",
    "nltk_sw = stopwords.words('english')\n",
    "sklearn_stop_words = sk_sw.ENGLISH_STOP_WORDS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Lenghs of Stop Words from file  571\n",
      "Lenghs of Stop Words from NLTK Library  179\n",
      "Lenghs of Stop Words from Sklearn Library  318\n"
     ]
    }
   ],
   "source": [
    "#Load from text file stop word for better performance\n",
    "#the stop words file was taking from http://members.unine.ch/jacques.savoy/clef/englishST.txt\n",
    "sw_list = []\n",
    "with open('StopWords.txt', 'r') as f:\n",
    "    [sw_list.append(word) for line in f for word in line.split()]\n",
    "\n",
    "print(\"Lenghs of Stop Words from file \", len(sw_list))\n",
    "print(\"Lenghs of Stop Words from NLTK Library \", len(nltk_sw))\n",
    "print(\"Lenghs of Stop Words from Sklearn Library \", len(sklearn_stop_words))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cleaning the texts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Remove blank rows if any.\n",
    "df['United'].dropna(inplace=True)\n",
    "\n",
    "# WordNetLemmatizer requires Pos tags to understand if the word is noun or verb or adjective etc. By default it is set to Noun\n",
    "tag_map = defaultdict(lambda: wn.NOUN)\n",
    "tag_map['J'] = wn.ADJ\n",
    "tag_map['V'] = wn.VERB\n",
    "tag_map['R'] = wn.ADV\n",
    "\n",
    "corpus = df['United']\n",
    "                  \n",
    "#Removing punctuations and numbers.                \n",
    "corpus = corpus.str.replace('[^\\w\\s]','') #punctuations\n",
    "corpus = corpus.str.replace('\\d+', '') #numbers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def text_preprocessing(text):\n",
    "    #Change all the text to lower case.\n",
    "    text = text.lower()\n",
    "\n",
    "    #Tokenization : In this each entry in the corpus will be broken into set of words\n",
    "    text_words_list = word_tokenize(text)\n",
    "\n",
    "    #Remove Stop words, Non-Numeric and perfom Word Stemming/Lemmenting.\n",
    "    #Declaring Empty List to store the words that follow the rules for this step\n",
    "    Final_words = []\n",
    "    \n",
    "    #Initializing WordNetLemmatizer()\n",
    "    word_Lemmatized = WordNetLemmatizer()\n",
    "    \n",
    "    # pos_tag function below will provide the 'tag' i.e if the word is Noun(N) or Verb(V) or something else.\n",
    "    for word, tag in pos_tag(text_words_list):\n",
    "        # Below condition is to check for Stop words and consider only alphabets\n",
    "        if word not in sw_list and word.isalpha():\n",
    "            word_Final = word_Lemmatized.lemmatize(word, tag_map[tag[0]])\n",
    "            Final_words.append(word_Final)\n",
    "    return str(Final_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['United'] = corpus.map(text_preprocessing)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating Word Cloud"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_word_cloud(input_text, mask, output_file_name, stopwords=None, extra_stopwords=None,\n",
    "                    bckgrd_color = \"white\", max_words=2000):\n",
    "\n",
    "    # Load the mask image\n",
    "    mask = np.array(Image.open(mask))\n",
    "    \n",
    "    # Load stop word list\n",
    "    stopwords = set(stopwords)\n",
    "    \n",
    "    # Add extra stop words if provided\n",
    "    if extra_stopwords is not None:\n",
    "        [stopwords.add(word) for word in extra_stopwords]\n",
    "    \n",
    "    # Call WordCloud\n",
    "    wc = WordCloud(background_color = bckgrd_color, max_words = max_words, collocations = False, relative_scaling=0,\n",
    "                   mode=\"RGBA\", mask = mask, stopwords = stopwords)\n",
    "\n",
    "    # Generate word cloud\n",
    "    wc.generate(input_text)\n",
    "    \n",
    "    # create coloring from image\n",
    "    image_colors = ImageColorGenerator(mask)\n",
    "    plt.figure(figsize=[7,7])\n",
    "    plt.imshow(wc.recolor(color_func=image_colors), interpolation=\"bilinear\")\n",
    "    plt.axis(\"off\")\n",
    "\n",
    "    # store to file\n",
    "    plt.savefig(output_file_name, format=\"png\")\n",
    "\n",
    "    plt.show()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tech = \" \".join(text for text in df[df[\"Label\"]==\"Technology\"].United)\n",
    "enter = \" \".join(text for text in df[df[\"Label\"]==\"Entertainment\"].United)\n",
    "busi = \" \".join(text for text in df[df[\"Label\"]==\"Business\"].United)\n",
    "heal = \" \".join(text for text in df[df[\"Label\"]==\"Health\"].United)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate a word cloud image for Techlonogy\n",
    "make_word_cloud(input_text = tech, mask = \"img/tech.jpg\", output_file_name = \"img/result_tech.png\", stopwords = sw_list)\n",
    "\n",
    "print(\"Word Cloud for Technology Label\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate a word cloud image for Techlonogy\n",
    "make_word_cloud(input_text = enter, mask = \"img/entertainment.png\", output_file_name = \"img/result_entertainment.png\", \n",
    "                stopwords = sw_list)\n",
    "\n",
    "print(\"Word Cloud for Entertainment Label\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate a word cloud image for Business \n",
    "make_word_cloud(input_text = busi, mask = \"img/business.jpg\", output_file_name = \"img/result_business.png\", stopwords = sw_list)\n",
    "\n",
    "print(\"Word Cloud for Business Label\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate a word cloud image for Health\n",
    "make_word_cloud(input_text = heal, mask = \"img/health.jpg\", output_file_name = \"img/result_health.png\", stopwords = sw_list)\n",
    "\n",
    "print(\"Word Cloud for Health Label\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Question 1b: Classification Task"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " ### Split the model into Train and Test Data set and Encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "Train_X, Test_X, Train_Y, Test_Y = model_selection.train_test_split(df['United'], df['Label'], test_size=0.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Label encode the target variable\n",
    "#This is done to transform Categorical data of string type in the data set into numerical values\n",
    "Encoder = LabelEncoder()\n",
    "Encoder.fit(Train_Y)\n",
    "Train_Y = Encoder.transform(Train_Y)\n",
    "Test_Y = Encoder.transform(Test_Y)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = Encoder.fit_transform(df['Label']) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0         ['netflix', 'come', 'cable', 'box', 'amazon', ...\n",
       "1         ['pharrell', 'iranian', 'president', 'react', ...\n",
       "2         ['wildlife', 'service', 'seek', 'comment', 'fi...\n",
       "3         ['facebook', 'team', 'storyful', 'launch', 'fb...\n",
       "4         ['caesar', 'plan', 'mln', 'york', 'casino', 'c...\n",
       "                                ...                        \n",
       "111790    ['microsoft', 'require', 'office', 'licensing'...\n",
       "111791    ['smallpox', 'vial', 'miss', 'find', 'lab', 's...\n",
       "111792    ['scientist', 'discover', 'key', 'reverse', 'a...\n",
       "111793    ['justin', 'bieber', 'plead', 'guilty', 'dui',...\n",
       "111794    ['tracy', 'morgan', 'upgrade', 'fair', 'condit...\n",
       "Name: United, Length: 111795, dtype: object"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['United']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating the Bag of Words (BoW)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CountVectorizer(max_features=10000)"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "count_vec = CountVectorizer(max_features = 10000)\n",
    "count_vec.fit(df['United'])\n",
    "count_vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "spare_matrix = count_vec.transform(df['United'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = spare_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "Train_X_Vec = count_vec.transform(Train_X)\n",
    "Test_X_Vec = count_vec.transform(Test_X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<78256x10000 sparse matrix of type '<class 'numpy.int64'>'\n",
       "\twith 9198022 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Train_X_Vec"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SVM (BoW)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SVC(gamma='auto', kernel='linear')"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "SVMClas_BoW = svm.SVC(C = 1.0, kernel = 'linear', degree = 3, gamma = 'auto')\n",
    "SVMClas_BoW.fit(Train_X_Vec, Train_Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# predict the labels on validation dataset\n",
    "predictions_SVM_BoW = SVMClas_BoW.predict(Test_X_Vec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "               precision    recall  f1-score   support\n",
      "\n",
      "Entertainment       0.89      0.91      0.90      7519\n",
      "   Technology       0.98      0.98      0.98     13464\n",
      "     Business       0.96      0.94      0.95      3674\n",
      "       Health       0.94      0.93      0.93      8882\n",
      "\n",
      "     accuracy                           0.95     33539\n",
      "    macro avg       0.94      0.94      0.94     33539\n",
      " weighted avg       0.95      0.95      0.95     33539\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(Test_Y, predictions_SVM_BoW, target_names = df['Label'].unique()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random Forests (BoW)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier()"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "RFClas_BoW = RandomForestClassifier(n_estimators = 100)\n",
    "RFClas_BoW.fit(Train_X_Vec, Train_Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# predict the labels on validation dataset\n",
    "predictions_RF_BoW = RFClas_BoW.predict(Test_X_Vec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "               precision    recall  f1-score   support\n",
      "\n",
      "Entertainment       0.91      0.90      0.91      7519\n",
      "   Technology       0.96      0.98      0.97     13464\n",
      "     Business       0.96      0.90      0.93      3674\n",
      "       Health       0.92      0.92      0.92      8882\n",
      "\n",
      "     accuracy                           0.94     33539\n",
      "    macro avg       0.94      0.93      0.93     33539\n",
      " weighted avg       0.94      0.94      0.94     33539\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(Test_Y, predictions_RF_BoW, target_names = df['Label'].unique()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### My Method - Logistic Regression "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(max_iter=10000, random_state=0)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "LGClas_BoW = LogisticRegression(max_iter = 10000, random_state = 0)\n",
    "LGClas_BoW.fit(Train_X_Vec, Train_Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions_LG_BoW = LGClas_BoW.predict(Test_X_Vec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "               precision    recall  f1-score   support\n",
      "\n",
      "Entertainment       0.92      0.92      0.92      7519\n",
      "   Technology       0.98      0.99      0.98     13464\n",
      "     Business       0.97      0.96      0.96      3674\n",
      "       Health       0.94      0.94      0.94      8882\n",
      "\n",
      "     accuracy                           0.96     33539\n",
      "    macro avg       0.95      0.95      0.95     33539\n",
      " weighted avg       0.96      0.96      0.96     33539\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(Test_Y, predictions_LG_BoW, target_names = df['Label'].unique()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating the Singular Value Decomposition (SVD)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TruncatedSVD(n_components=5, n_iter=7, random_state=42)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "svd = TruncatedSVD(n_components = 5, n_iter = 7, random_state = 42)\n",
    "svd.fit(spare_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 3.00349290e+00, -3.60326463e-01,  3.73416219e-03,\n",
       "         1.61444397e+00, -5.84706006e-01],\n",
       "       [ 2.04676370e+00,  4.79730706e-02, -6.36475373e-01,\n",
       "        -5.01986644e-01,  1.25071841e-01],\n",
       "       [ 3.99276871e+00,  1.38119389e-01, -8.50946907e-02,\n",
       "         1.08318056e+00,  1.56007403e+00],\n",
       "       ...,\n",
       "       [ 4.73855162e+00, -1.07045394e-02, -1.80324545e+00,\n",
       "        -2.19784195e+00,  5.40502806e+00],\n",
       "       [ 1.44973560e+00, -2.18431832e-02, -5.85598230e-01,\n",
       "        -3.63746721e-01, -2.23043373e-02],\n",
       "       [ 1.37615154e+00,  2.81094068e-01, -5.73145649e-01,\n",
       "        -5.01959499e-01,  3.00647377e-01]])"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "svd.transform(spare_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "Train_X_svd = svd.transform(Train_X_Vec)\n",
    "Test_X_svd = svd.transform(Test_X_Vec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Test_X_svd.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(78256,)"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Train_Y.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SVM (SVD)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SVC(gamma='auto', kernel='linear')"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "SVMClas_SVD = svm.SVC(C = 1.0, kernel = 'linear', degree = 3, gamma = 'auto')\n",
    "SVMClas_SVD.fit(Train_X_svd, Train_Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# predict the labels on validation dataset\n",
    "predictions_SVM_SVD = SVMClas_SVD.predict(Test_X_svd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "               precision    recall  f1-score   support\n",
      "\n",
      "Entertainment       0.82      0.73      0.78      7519\n",
      "   Technology       0.86      0.95      0.90     13464\n",
      "     Business       0.82      0.75      0.78      3674\n",
      "       Health       0.75      0.73      0.74      8882\n",
      "\n",
      "     accuracy                           0.82     33539\n",
      "    macro avg       0.81      0.79      0.80     33539\n",
      " weighted avg       0.82      0.82      0.82     33539\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(Test_Y, predictions_SVM_SVD, target_names = df['Label'].unique()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random Forests (SVD)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier()"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "RFClas_SVD = RandomForestClassifier(n_estimators = 100)\n",
    "RFClas_SVD.fit(Train_X_svd, Train_Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions_RF_SVD = RFClas_SVD.predict(Test_X_svd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(classification_report(Test_Y, predictions_RF_SVD, target_names = df['Label'].unique()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### My Method - Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(max_iter=10000, random_state=0)"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "LGClas_SVD = LogisticRegression(max_iter = 10000, random_state = 0)\n",
    "LGClas_SVD.fit(Train_X_svd, Train_Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions_LG_SVD = LGClas_SVD.predict(Test_X_svd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(classification_report(Test_Y, predictions_LG_SVD, target_names = df['Label'].unique()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5-Fold Cross Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "               precision    recall  f1-score   support\n",
      "\n",
      "Entertainment       0.91      0.90      0.90      5070\n",
      "   Technology       0.98      0.98      0.98      8964\n",
      "     Business       0.95      0.96      0.96      2348\n",
      "       Health       0.92      0.94      0.93      5977\n",
      "\n",
      "     accuracy                           0.95     22359\n",
      "    macro avg       0.94      0.94      0.94     22359\n",
      " weighted avg       0.95      0.95      0.95     22359\n",
      "\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "Entertainment       0.92      0.90      0.91      5150\n",
      "   Technology       0.98      0.98      0.98      8920\n",
      "     Business       0.94      0.96      0.95      2379\n",
      "       Health       0.92      0.94      0.93      5910\n",
      "\n",
      "     accuracy                           0.95     22359\n",
      "    macro avg       0.94      0.94      0.94     22359\n",
      " weighted avg       0.95      0.95      0.95     22359\n",
      "\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "Entertainment       0.91      0.89      0.90      4986\n",
      "   Technology       0.98      0.98      0.98      8940\n",
      "     Business       0.95      0.95      0.95      2427\n",
      "       Health       0.93      0.93      0.93      6006\n",
      "\n",
      "     accuracy                           0.95     22359\n",
      "    macro avg       0.94      0.94      0.94     22359\n",
      " weighted avg       0.95      0.95      0.95     22359\n",
      "\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "Entertainment       0.92      0.89      0.90      5035\n",
      "   Technology       0.98      0.98      0.98      9100\n",
      "     Business       0.95      0.96      0.95      2332\n",
      "       Health       0.92      0.94      0.93      5892\n",
      "\n",
      "     accuracy                           0.95     22359\n",
      "    macro avg       0.94      0.94      0.94     22359\n",
      " weighted avg       0.95      0.95      0.95     22359\n",
      "\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "Entertainment       0.92      0.90      0.91      5157\n",
      "   Technology       0.98      0.98      0.98      8948\n",
      "     Business       0.94      0.96      0.95      2401\n",
      "       Health       0.92      0.94      0.93      5853\n",
      "\n",
      "     accuracy                           0.95     22359\n",
      "    macro avg       0.94      0.94      0.94     22359\n",
      " weighted avg       0.95      0.95      0.95     22359\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import KFold\n",
    "\n",
    "kf = KFold(n_splits = 5)\n",
    "SVMClf = svm.SVC(C = 1.0, kernel = 'linear', degree = 3, gamma = 'auto')\n",
    "for train_index, test_index in kf.split(df['United'], df['Label']):\n",
    "    X_train_counts = count_vec.transform(np.array(df['United'])[train_index])\n",
    "    X_test_counts = count_vec.transform(np.array(df['United'])[test_index])\n",
    "    \n",
    "    clf_cv = SVMClf.fit(X_train_counts, np.array(df['Label'])[train_index])\n",
    "    yPred = clf_cv.predict(X_test_counts)\n",
    "    yTrue = np.array(df['Label'])[test_index]\n",
    "    print(classification_report(yPred, yTrue, target_names = df['Label'].unique()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using pipelines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "\n",
    "SVM_bow = Pipeline([(\"SVM\", svm.SVC(C = 1.0, kernel = 'linear', degree = 3, gamma = 'auto'))])\n",
    "RF_bow = Pipeline([(\"Random Forest\", RandomForestClassifier(n_estimators = 100))])\n",
    "SVM_svd = Pipeline([('feat', TruncatedSVD(n_components = 5, n_iter = 7, random_state = 42)), (\"SVM\", svm.SVC(C = 1.0, kernel = 'linear', degree = 3, gamma = 'auto'))])\n",
    "RF_svd = Pipeline([('feat', TruncatedSVD(n_components = 5, n_iter = 7, random_state = 42)), (\"Random Forest\", RandomForestClassifier(n_estimators = 100))])\n",
    "LR_bow = Pipeline([(\"Logistic Regression\", LogisticRegression(max_iter = 10000, random_state = 0))])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "models=[\n",
    "    (\"SVM (BoW)\", SVM_bow),\n",
    "    (\"Random Forest (BoW)\", RF_bow),\n",
    "    (\"SVM (SVD)\", SVM_svd),\n",
    "    (\"Random Forest (SVD)\", RF_svd),\n",
    "    (\"My Method\", LR_bow)\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Model evaluation function\n",
    "d = {'Statistic Measure': ['Accuracy', 'Precision', 'Recall', 'F-Measure']}\n",
    "evaluation = pd.DataFrame(data=d).set_index('Statistic Measure')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-86-de8204c44c61>:4: DeprecationWarning: The default dtype for empty Series will be 'object' instead of 'float64' in a future version. Specify a dtype explicitly to silence this warning.\n",
      "  s = pd.Series()\n",
      "<ipython-input-86-de8204c44c61>:4: DeprecationWarning: The default dtype for empty Series will be 'object' instead of 'float64' in a future version. Specify a dtype explicitly to silence this warning.\n",
      "  s = pd.Series()\n",
      "<ipython-input-86-de8204c44c61>:4: DeprecationWarning: The default dtype for empty Series will be 'object' instead of 'float64' in a future version. Specify a dtype explicitly to silence this warning.\n",
      "  s = pd.Series()\n",
      "<ipython-input-86-de8204c44c61>:4: DeprecationWarning: The default dtype for empty Series will be 'object' instead of 'float64' in a future version. Specify a dtype explicitly to silence this warning.\n",
      "  s = pd.Series()\n"
     ]
    }
   ],
   "source": [
    "# Applying K-folds for pipeline\n",
    "kf = KFold(n_splits=5)\n",
    "for name, model in models:\n",
    "\ts = pd.Series()\n",
    "\tfor train, test in kf.split(spare_matrix):\n",
    "\t\tX_train, X_test = X[train], X[test]\n",
    "\t\ty_train, y_test = y[train], y[test]\n",
    "\t\ttrain = model.fit(X_train, y_train)\n",
    "\t\typred = model.predict(X_test)\n",
    "\td = [accuracy_score(y_test, ypred), precision_score(y_test, ypred, average = 'macro'), recall_score(y_test, ypred, average = 'macro'), f1_score(y_test, ypred, average = 'macro')]\n",
    "\tevaluation[name] = d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "d = [accuracy_score(y_test, ypred), precision_score(y_test, ypred, average = 'macro'), recall_score(y_test, ypred, average = 'macro'), f1_score(y_test, ypred, average = 'macro')]\n",
    "evaluation[name] = d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(evaluation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluation.to_csv('5fold_1a.csv', sep = ',')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preporcessing test dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data = pd.read_csv('test_without_labels.csv', sep = ',')\n",
    "test_data['United'] = test_data['Title'] + ' ' + test_data['Content']\n",
    "\n",
    "#Remove blank rows if any.\n",
    "test_data['United'].dropna(inplace=True)\n",
    "\n",
    "# WordNetLemmatizer requires Pos tags to understand if the word is noun or verb or adjective etc. By default it is set to Noun\n",
    "tag_map = defaultdict(lambda: wn.NOUN)\n",
    "tag_map['J'] = wn.ADJ\n",
    "tag_map['V'] = wn.VERB\n",
    "tag_map['R'] = wn.ADV\n",
    "\n",
    "corpus_test = test_data['United']\n",
    "                  \n",
    "#Removing punctuations and numbers.                \n",
    "corpus_test = corpus_test.str.replace('[^\\w\\s]','') #punctuations\n",
    "corpus_test = corpus_test.str.replace('\\d+', '') #numbers\n",
    "\n",
    "test_data['United'] = corpus_test.map(text_preprocessing)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  (0, 53)\t1\n",
      "  (0, 100)\t1\n",
      "  (0, 510)\t1\n",
      "  (0, 559)\t1\n",
      "  (0, 571)\t1\n",
      "  (0, 651)\t2\n",
      "  (0, 678)\t1\n",
      "  (0, 698)\t1\n",
      "  (0, 713)\t1\n",
      "  (0, 770)\t1\n",
      "  (0, 842)\t1\n",
      "  (0, 1148)\t2\n",
      "  (0, 1466)\t1\n",
      "  (0, 1585)\t1\n",
      "  (0, 1745)\t3\n",
      "  (0, 1808)\t1\n",
      "  (0, 1816)\t1\n",
      "  (0, 1852)\t4\n",
      "  (0, 1887)\t1\n",
      "  (0, 2101)\t4\n",
      "  (0, 2127)\t1\n",
      "  (0, 2134)\t1\n",
      "  (0, 2299)\t1\n",
      "  (0, 2727)\t1\n",
      "  (0, 2728)\t1\n",
      "  :\t:\n",
      "  (47911, 7795)\t3\n",
      "  (47911, 7807)\t1\n",
      "  (47911, 7945)\t2\n",
      "  (47911, 8418)\t2\n",
      "  (47911, 8429)\t1\n",
      "  (47911, 8478)\t9\n",
      "  (47911, 8485)\t1\n",
      "  (47911, 8504)\t1\n",
      "  (47911, 8522)\t1\n",
      "  (47911, 8561)\t3\n",
      "  (47911, 8588)\t1\n",
      "  (47911, 8806)\t1\n",
      "  (47911, 8809)\t4\n",
      "  (47911, 8880)\t2\n",
      "  (47911, 9071)\t2\n",
      "  (47911, 9099)\t1\n",
      "  (47911, 9277)\t1\n",
      "  (47911, 9327)\t1\n",
      "  (47911, 9452)\t1\n",
      "  (47911, 9528)\t1\n",
      "  (47911, 9702)\t1\n",
      "  (47911, 9827)\t6\n",
      "  (47911, 9882)\t1\n",
      "  (47911, 9936)\t1\n",
      "  (47911, 9963)\t2\n"
     ]
    }
   ],
   "source": [
    "test  = count_vec.transform(test_data['United'])\n",
    "id_n = test_data['Id']\n",
    "print(test)\n",
    "predictions = RFClas_BoW.predict(test)\n",
    "prediction_table = pd.DataFrame(data = id_n, columns = ['Id'])\n",
    "prediction_table['Predicted'] = predictions\n",
    "\n",
    "for i in range(prediction_table.shape[0]):\n",
    "    if prediction_table['Predicted'][i] == 0:\n",
    "        prediction_table['Predicted'][i] = 'Business'\n",
    "    if prediction_table['Predicted'][i] == 1:\n",
    "        prediction_table['Predicted'][i] = 'Entertainment'\n",
    "    if prediction_table['Predicted'][i] == 2:\n",
    "        prediction_table['Predicted'][i] = 'Health'\n",
    "    if prediction_table['Predicted'][i] == 3:\n",
    "        prediction_table['Predicted'][i] = 'Technology'\n",
    "        \n",
    "prediction_table.to_csv('testSet_categories_1b.csv', sep =',', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
